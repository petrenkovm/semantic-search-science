Generative models such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) have enabled the synthesis of realistic data across modalities. In image generation, GANs produce high-fidelity visuals, while VAEs offer latent space manipulation for controlled outputs. Recent advances include diffusion models, which iteratively refine noise to generate coherent samples, outperforming previous architectures in quality and diversity.